# set image size
image_size: &image_size 512

# set dir or path
dataset:
  use: "Hdf5Dataset"
  XRayDataset:
    image_dir: "/opt/ml/input/data/train/DCM"
    label_dir: "/opt/ml/input/data/train/outputs_json"
  NpzDataset:
    image_dir: "/opt/ml/input/data/train/DCM"
    label_dir: "/opt/ml/input/data/train/outputs_json"
  CacheDataset:
    cache_dir: "/opt/ml/input/cache_data_512"
  Hdf5Dataset:
    hdf5_dir: "/opt/ml/input/hdf5_data_512"

test_image_dir: "/opt/ml/input/data/test/DCM"
save_model_dir: "/opt/ml/input/results"
resume_model_dir: False
inference_model_dir: "/opt/ml/input/results/hrnet_512_0"

# set model
model: 
  use: "pytorch"
  smp:
    architectures: "UnetPlusPlus"
    encoder_name: "inceptionv4"
    encoder_weights: "imagenet"
    model_info: *image_size
  pytorch:
    architectures: "hrnet"
    model_info: *image_size

# set hyperparameter
seed: 42
epochs: 500
train:
  batch_size: 8
  num_workers: 4
  augmentation:
    - type: "Resize"
      parameters:
        height: *image_size
        width: *image_size
        p: 1.0
    # - type: "HorizontalFlip"
    #   parameters:
    #     p: 0.5
valid:
  batch_size: 4
  num_workers: 2
  augmentation:
    - type: "Resize"
      parameters:
        height: *image_size
        width: *image_size
        p: 1.0
test:
  batch_size: 1
  num_workers: 8
  augmentation:
    - type: "Resize"
      parameters:
        height: *image_size
        width: *image_size
        p: 1.0

optimizer:
  optim: "Adam"
  learning_rate: 0.0001   # 1e-4
  weight_decay: 0.000001  # 1e-6
scheduler:
  type: "ReduceLROnPlateau"
  parameters:
    mode: "max"
    factor: 0.5
    patience: 50

loss: "BCEWithLogitsLoss"
fp16: True

# set log
wandb: 
  use: False
  entity: "kgw5430"
  project: "semantic-segmentation"
  name: "base"
log_step: 20
val_every: 1
patience_limit: 200