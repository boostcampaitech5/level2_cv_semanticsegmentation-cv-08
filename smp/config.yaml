# set dir or path
dataset:
  use: "Hdf5Dataset"

  XRayDataset:
    image_dir: "/opt/ml/input/data/train/DCM"
    label_dir: "/opt/ml/input/data/train/outputs_json"
  NpzDataset:
    image_dir: "/opt/ml/input/data/train/DCM"
    label_dir: "/opt/ml/input/data/train/outputs_json"
  CacheDataset:
    cache_dir: "/opt/ml/input/data_cache_1024"
  Hdf5Dataset:
    hdf5_dir: "/opt/ml/input/data_hdf5_1024"

test_image_dir: "/opt/ml/input/data/test/DCM"
save_model_dir: "/opt/ml/input/results"
test_model_dir_num: null # 저장된 모델 dir의 번호를 명시적으로 선언 (inference 할 때 사용)

# set model
model: "UnetPlusPlus"
encoder_name: "resnet50"
encoder_weights: "imagenet"
model_info: "ValidCheck"
resume: False

# set hyperparameter
seed: 42
epochs: 500
train:
  batch_size: 4
  num_workers: 2
valid:
  batch_size: 2
  num_workers: 2
test:
  batch_size: 1
  num_workers: 8
optimizer:
  optim: "Adam"
  learning_rate: 0.0001   # 1e-4
  weight_decay: 0.000001  # 1e-6
loss: "BCEWithLogitsLoss"
fp16: True

# set log
wandb: 
  use: False
  entity: "kgw5430"
  project: "semantic-segmentation"
  name: "base"
log_step: 20
val_every: 5
patience_limit: 5