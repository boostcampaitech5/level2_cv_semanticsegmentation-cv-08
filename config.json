{
    "base": {
        "use": "smp",
        "pytorch": {
            "model": "unet"
        },
        "smp": {
            "model": "UnetPlusPlus",
            "encoder_name": "resnet50",
            "encoder_weights": "imagenet"
        }
    },
    "save_model_dir": "/opt/ml/level2_cv_semanticsegmentation-cv-08/model_dir/unet+++_512_BCE-Dice_adamw",
    "inference_model_dir": "/opt/ml/level2_cv_semanticsegmentation-cv-08/model_dir/unet+++_512-BCE-Dice_adamw",
    "model_file_name": "best.pth",
    "resume_from": "/opt/ml/input/results/UnetPlusPlus_resnet50/best.pt",
    "dataset": "Hdf5Dataset",
    "image_dir": "/opt/ml/data/train/DCM",
    "label_dir": "/opt/ml/data/train/outputs_json",
    "test_image_dir": "/opt/ml/data/test/DCM",
    "train_json_path": "/opt/ml/data/train_split.json",
    "valid_json_path": "/opt/ml/data/valid_split.json",
    "train_cache_data_dir": "/opt/ml/cache_data_512/train",
    "valid_cache_data_dir": "/opt/ml/cache_data_512/valid",
    "train_hdf5_data_dir": "/opt/ml/hdf5_512/train",
    "valid_hdf5_data_dir": "/opt/ml/hdf5_512/valid",
    "epochs": 120,
    "train": {
        "batch_size": 8,
        "num_workers": 4,
        "augmentations": {
            "name": "base_augmentation",
            "parameters": {
                "resize": 512
            }
        }
    },
    "valid": {
        "batch_size": 4,
        "num_workers": 2,
        "augmentations": {
            "name": "base_augmentation",
            "parameters": {
                "resize": 512
            }
        }
    },
    "test": {
        "batch_size": 1,
        "num_workers": 8,
        "augmentations": {
            "name": "base_augmentation",
            "parameters": {
                "resize": 512
            }
        }
    },
    "optimizer": {
        "type": "AdamW",
        "parameters": {
            "lr": 0.0001,
            "weight_decay": 1e-06
        }
    },
    "criterion": "BCEWithLogitsLoss",
    "scheduler": {
        "type": "MultiStepLR",
        "parameters": {
            "milestones": [
                100,
                110
            ],
            "gamma": 0.5
        }
    },
    "seed": 42,
    "log_step": 20,
    "val_every": 1,
    "patience_limit": 20,
    "accumulation_step": 1,
    "fp16": true,
    "wandb": {
        "use": false,
        "entity": "ejrtks1020",
        "project": "level2_segmentation",
        "run_name": "unet+++_512-BCE-Dice_adamw"
    }
}