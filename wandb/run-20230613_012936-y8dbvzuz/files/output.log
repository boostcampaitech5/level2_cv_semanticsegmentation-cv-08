
Start trainig.....
2023-06-13 01:29:50 |  Epoch [1/500],  Step [2/80],  Loss: 0.7037
2023-06-13 01:29:52 |  Epoch [1/500],  Step [4/80],  Loss: 0.6896
2023-06-13 01:29:53 |  Epoch [1/500],  Step [6/80],  Loss: 0.6844
2023-06-13 01:29:54 |  Epoch [1/500],  Step [8/80],  Loss: 0.6806
2023-06-13 01:29:55 |  Epoch [1/500],  Step [10/80],  Loss: 0.6766
2023-06-13 01:29:56 |  Epoch [1/500],  Step [12/80],  Loss: 0.6721
2023-06-13 01:29:57 |  Epoch [1/500],  Step [14/80],  Loss: 0.6671
2023-06-13 01:29:58 |  Epoch [1/500],  Step [16/80],  Loss: 0.6613
2023-06-13 01:29:59 |  Epoch [1/500],  Step [18/80],  Loss: 0.6546
2023-06-13 01:30:01 |  Epoch [1/500],  Step [20/80],  Loss: 0.6468
2023-06-13 01:30:02 |  Epoch [1/500],  Step [22/80],  Loss: 0.6379
2023-06-13 01:30:03 |  Epoch [1/500],  Step [24/80],  Loss: 0.6278
2023-06-13 01:30:04 |  Epoch [1/500],  Step [26/80],  Loss: 0.6166
2023-06-13 01:30:05 |  Epoch [1/500],  Step [28/80],  Loss: 0.6041
2023-06-13 01:30:06 |  Epoch [1/500],  Step [30/80],  Loss: 0.5902
2023-06-13 01:30:07 |  Epoch [1/500],  Step [32/80],  Loss: 0.575
2023-06-13 01:30:09 |  Epoch [1/500],  Step [34/80],  Loss: 0.5587
2023-06-13 01:30:10 |  Epoch [1/500],  Step [36/80],  Loss: 0.541
2023-06-13 01:30:11 |  Epoch [1/500],  Step [38/80],  Loss: 0.5222
2023-06-13 01:30:12 |  Epoch [1/500],  Step [40/80],  Loss: 0.5025
2023-06-13 01:30:13 |  Epoch [1/500],  Step [42/80],  Loss: 0.4819
2023-06-13 01:30:14 |  Epoch [1/500],  Step [44/80],  Loss: 0.4605
2023-06-13 01:30:15 |  Epoch [1/500],  Step [46/80],  Loss: 0.4382
2023-06-13 01:30:17 |  Epoch [1/500],  Step [48/80],  Loss: 0.4157
2023-06-13 01:30:18 |  Epoch [1/500],  Step [50/80],  Loss: 0.3933
2023-06-13 01:30:19 |  Epoch [1/500],  Step [52/80],  Loss: 0.3705
2023-06-13 01:30:20 |  Epoch [1/500],  Step [54/80],  Loss: 0.3481
2023-06-13 01:30:21 |  Epoch [1/500],  Step [56/80],  Loss: 0.3258
2023-06-13 01:30:22 |  Epoch [1/500],  Step [58/80],  Loss: 0.304
2023-06-13 01:30:24 |  Epoch [1/500],  Step [60/80],  Loss: 0.283
2023-06-13 01:30:25 |  Epoch [1/500],  Step [62/80],  Loss: 0.2622
2023-06-13 01:30:26 |  Epoch [1/500],  Step [64/80],  Loss: 0.2428
2023-06-13 01:30:27 |  Epoch [1/500],  Step [66/80],  Loss: 0.2252
2023-06-13 01:30:28 |  Epoch [1/500],  Step [68/80],  Loss: 0.208
2023-06-13 01:30:29 |  Epoch [1/500],  Step [70/80],  Loss: 0.1916
2023-06-13 01:30:30 |  Epoch [1/500],  Step [72/80],  Loss: 0.1772
2023-06-13 01:30:32 |  Epoch [1/500],  Step [74/80],  Loss: 0.1639
2023-06-13 01:30:33 |  Epoch [1/500],  Step [76/80],  Loss: 0.1514
2023-06-13 01:30:34 |  Epoch [1/500],  Step [78/80],  Loss: 0.1398
2023-06-13 01:30:35 |  Epoch [1/500],  Step [80/80],  Loss: 0.1299
current learning rate :  0.000998
finger-1    : 0.0000
finger-2    : 0.0000
finger-3    : 0.0000
finger-4    : 0.0000
finger-5    : 0.0000
finger-6    : 0.0111
finger-7    : 0.0000
finger-8    : 0.0000
finger-9    : 0.0000
finger-10   : 0.0000
finger-11   : 0.0000
finger-12   : 0.0000
finger-13   : 0.0000
finger-14   : 0.0000
finger-15   : 0.0000
finger-16   : 0.0000
finger-17   : 0.0000
finger-18   : 0.0000
finger-19   : 0.0000
Trapezium   : 0.0000
Trapezoid   : 0.0000
Capitate    : 0.0000
Hamate      : 0.0000
Scaphoid    : 0.0000
Lunate      : 0.0000
Triquetrum  : 0.0000
Pisiform    : 0.0000
Radius      : 0.0000
Ulna        : 0.0120
Best performance at epoch: 1, 0.0000 -> 0.0008
Save model in ./model_dir
2023-06-13 01:30:59 |  Epoch [2/500],  Step [2/80],  Loss: 0.1205
2023-06-13 01:31:00 |  Epoch [2/500],  Step [4/80],  Loss: 0.1114
2023-06-13 01:31:01 |  Epoch [2/500],  Step [6/80],  Loss: 0.1048
2023-06-13 01:31:02 |  Epoch [2/500],  Step [8/80],  Loss: 0.0965
2023-06-13 01:31:03 |  Epoch [2/500],  Step [10/80],  Loss: 0.0901
2023-06-13 01:31:04 |  Epoch [2/500],  Step [12/80],  Loss: 0.085
2023-06-13 01:31:05 |  Epoch [2/500],  Step [14/80],  Loss: 0.0797
2023-06-13 01:31:07 |  Epoch [2/500],  Step [16/80],  Loss: 0.0759
2023-06-13 01:31:08 |  Epoch [2/500],  Step [18/80],  Loss: 0.072
2023-06-13 01:31:09 |  Epoch [2/500],  Step [20/80],  Loss: 0.0679
2023-06-13 01:31:10 |  Epoch [2/500],  Step [22/80],  Loss: 0.0639
2023-06-13 01:31:11 |  Epoch [2/500],  Step [24/80],  Loss: 0.0612
2023-06-13 01:31:12 |  Epoch [2/500],  Step [26/80],  Loss: 0.0592
2023-06-13 01:31:13 |  Epoch [2/500],  Step [28/80],  Loss: 0.0574
2023-06-13 01:31:15 |  Epoch [2/500],  Step [30/80],  Loss: 0.0542
2023-06-13 01:31:16 |  Epoch [2/500],  Step [32/80],  Loss: 0.0515
2023-06-13 01:31:17 |  Epoch [2/500],  Step [34/80],  Loss: 0.0513
2023-06-13 01:31:18 |  Epoch [2/500],  Step [36/80],  Loss: 0.0491
2023-06-13 01:31:19 |  Epoch [2/500],  Step [38/80],  Loss: 0.0468
2023-06-13 01:31:20 |  Epoch [2/500],  Step [40/80],  Loss: 0.0458
2023-06-13 01:31:21 |  Epoch [2/500],  Step [42/80],  Loss: 0.0445
2023-06-13 01:31:23 |  Epoch [2/500],  Step [44/80],  Loss: 0.0429
2023-06-13 01:31:24 |  Epoch [2/500],  Step [46/80],  Loss: 0.0422
2023-06-13 01:31:25 |  Epoch [2/500],  Step [48/80],  Loss: 0.0413
2023-06-13 01:31:26 |  Epoch [2/500],  Step [50/80],  Loss: 0.0402
2023-06-13 01:31:27 |  Epoch [2/500],  Step [52/80],  Loss: 0.0396
2023-06-13 01:31:28 |  Epoch [2/500],  Step [54/80],  Loss: 0.0373
2023-06-13 01:31:30 |  Epoch [2/500],  Step [56/80],  Loss: 0.0376
2023-06-13 01:31:31 |  Epoch [2/500],  Step [58/80],  Loss: 0.0368
2023-06-13 01:31:32 |  Epoch [2/500],  Step [60/80],  Loss: 0.0367
2023-06-13 01:31:33 |  Epoch [2/500],  Step [62/80],  Loss: 0.0348
2023-06-13 01:31:34 |  Epoch [2/500],  Step [64/80],  Loss: 0.0344
2023-06-13 01:31:36 |  Epoch [2/500],  Step [66/80],  Loss: 0.035
2023-06-13 01:31:37 |  Epoch [2/500],  Step [68/80],  Loss: 0.1366
2023-06-13 01:31:38 |  Epoch [2/500],  Step [70/80],  Loss: 0.4594
2023-06-13 01:31:39 |  Epoch [2/500],  Step [72/80],  Loss: 0.0516
2023-06-13 01:31:41 |  Epoch [2/500],  Step [74/80],  Loss: 0.0432
2023-06-13 01:31:42 |  Epoch [2/500],  Step [76/80],  Loss: 0.047
2023-06-13 01:31:43 |  Epoch [2/500],  Step [78/80],  Loss: 0.0361
2023-06-13 01:31:44 |  Epoch [2/500],  Step [80/80],  Loss: 0.0361
current learning rate :  0.000996
Traceback (most recent call last):
  File "train.py", line 151, in <module>
    main(config)
  File "train.py", line 110, in main
    masks = masks.detach().cpu()
KeyboardInterrupt